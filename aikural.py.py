# -*- coding: utf-8 -*-
"""generate.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1M41MRRAREyfpY4r2j1xFS32BjvxP3jxU
"""

import torch
import torch.nn as nn

device = (torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu"))
device

!wget https://github.com/devic1/Ai-Kural/raw/main/data.zip

!unzip data.zip

import torch 
import torch.nn as nn
import os
import pandas as pd

cd = pd.read_csv("/content/Thirukural.csv")

rd = cd["Verse"].values
data = []
for i in rd:
  i = i.replace("\t"," ")
  i = i.replace("   "," ")
  data.append(i[:-1])
data

lett = set()
for i in data:
  for j in i:
    lett.add(j)
lett.add(".")

ltoi = {i:k for k,i in enumerate(sorted(lett))}
ll_n = len(ltoi)
print(ltoi)
ll_n

itol = {l:k for k,l in ltoi.items()}
print(itol)

class RNN(nn.Module):
  def __init__(self,inp_size,hid_size,out_size):
    super().__init__()
    self.inp_size = inp_size
    self.hid_size = hid_size
    self.out_size = out_size
    self.i2h = nn.Linear(self.inp_size+self.hid_size,self.hid_size)
    self.i2o = nn.Linear(self.inp_size+self.hid_size,self.out_size)
    self.o2o = nn.Linear(self.hid_size+self.out_size,self.out_size)
    self.drop = nn.Dropout(0.1)
    self.softmax = nn.LogSoftmax(dim=1)
  
  def forward(self,inp,hid):
    combined_out = torch.cat((inp,hid),dim=1)
    hid_1 = self.i2h(combined_out)
    out = self.i2o(combined_out)
    combined_sec = torch.cat((hid_1,out),1)
    x = self.o2o(combined_sec)
    x = self.drop(x)
    x = self.softmax(x)
    return x,hid_1

  def temp_hidden(self):
    return torch.zeros(1,self.hid_size)

rnn = RNN(ll_n,128,ll_n).to(device)

def one_enc(lett):
  return torch.nn.functional.one_hot(torch.tensor(ltoi[lett]),num_classes=ll_n).unsqueeze(0)

lente = len(data)
def getrandinp():
  randn = torch.randint(0,lente,(1,))
  inp = torch.tensor([])
  out = torch.tensor([],dtype=torch.long)
  word = data[randn]
  for i,j in zip(word,word[1:]+"."):
    tens = one_enc(i)
    inp = torch.cat((inp,tens),0)
    teno = torch.tensor(ltoi[j]).unsqueeze(0)
    out = torch.cat((out,teno))
  return inp,out.unsqueeze(1),word

loss_fn = nn.NLLLoss()
optimizer = torch.optim.SGD(rnn.parameters(),lr=0.001)

epoch = 40000
rnn.train()
for num in range(epoch):
  hid = rnn.temp_hidden()
  inp,tar,word = getrandinp()
  inp,tar,hid = inp.to(device),tar.to(device),hid.to(device)
  loss = 0
  for i in range(len(word)):
    out,hid = rnn(inp[i].unsqueeze(0),hid)
    loss += loss_fn(out,tar[i])
  if torch.isnan(loss):
    print(inp.shape)
    print(loss)
    print(word)
    break
  optimizer.zero_grad()
  loss.backward()
  optimizer.step()
  if num%(epoch/10) == 0:
    print(f'{loss/len(word)} is the loss for {num+1}th time')

rnn.eval()
with torch.no_grad():
  for i in range(10):
    #t = input("Enter a continuous letter : ")
    t = itol[torch.randint(5,ll_n,(1,)).item()]
    hid = rnn.temp_hidden()
    hid = hid.to(device)
    real_out = ""
    while True:
      n = one_enc(t)
      n = n.to(device)
      out,hid = rnn(n,hid)
      _,result = out.topk(3)
      res = result[0][torch.randint(0,3,(1,))].item()
      real_out += t
      if itol[res] == ".":
        break
      t = itol[res]
    print(real_out)

torch.save(rnn.state_dict(), "/content/drive/MyDrive/college/rnn_model_thirukural.pt")

print("Happy Ending :)")

